{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vZXLivsLYkb4"
      },
      "outputs": [],
      "source": [
        "##CALTEXT code with elimination of extra biases\n",
        "from itertools import chain\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D\n",
        "from tensorflow.keras import Model\n",
        "import pickle  as pkl\n",
        "import numpy as np\n",
        "import re\n",
        "import math\n",
        "import copy\n",
        "import random\n",
        "import time\n",
        "import os\n",
        "from tensorflow.keras import layers\n",
        "#import data\n",
        "rng = np.random.RandomState(int(time.time()))\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "from skimage.transform import rescale, resize\n",
        "from matplotlib import gridspec"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#mount with google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0hdYMvI1Y6qS",
        "outputId": "90aada96-6f79-4ebd-f34c-c981df60e91f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "################################### Utility functions###################################\n",
        "####  load_data(): used for loading of pickle files as batches\n",
        "def load_data(images_file, label_file):\n",
        "  fp=open(images_file,'rb')\n",
        "  features=pkl.load(fp)\n",
        "  print(len(features))\n",
        "  fp.close()\n",
        "\n",
        "  fp2=open(label_file,'rb')\n",
        "  targets=pkl.load(fp2)\n",
        "  fp2.close()\n",
        "\n",
        "\n",
        "  imageSize={}\n",
        "  for uid,fea in features.items():\n",
        "    imageSize[uid]=fea.shape[0]*fea.shape[1]\n",
        "\n",
        "\n",
        "  feature_batch=[]\n",
        "  label_batch=[]\n",
        "  feature_total=[]\n",
        "  label_total=[]\n",
        "  uidList=[]\n",
        "  imageSize= sorted(imageSize.items(), key=lambda d:d[1]) # sorted by sentence length,  return a list with each triple element\n",
        "\n",
        "  batch_image_size=0\n",
        "  biggest_image_size=0\n",
        "  i=0\n",
        "  for uid,size in imageSize:\n",
        "    fea=features[uid]\n",
        "    lab=targets[int(uid)]\n",
        "    uidList.append(uid)\n",
        "    if i==batch_size: # a batch is full\n",
        "            feature_total.append(feature_batch)\n",
        "            label_total.append(label_batch)\n",
        "            i=0\n",
        "            feature_batch=[]\n",
        "            label_batch=[]\n",
        "            feature_batch.append(fea)\n",
        "            label_batch.append(lab)\n",
        "            i+=1\n",
        "    else:\n",
        "            feature_batch.append(fea)\n",
        "            label_batch.append(lab)\n",
        "            i+=1\n",
        "\n",
        "    # last batch\n",
        "  feature_total.append(feature_batch)\n",
        "  label_total.append(label_batch)\n",
        "\n",
        "  print('total ',len(feature_total), 'batch data loaded')\n",
        "\n",
        "  return list(zip(feature_total,label_total)),uidList\n",
        "\n",
        "####  prepare(): prepare function makes sure that size of images and labels is same in a batch, also creates masks for images and labels.\n",
        "def prepare(images, labels):\n",
        "  heights_x = [s.shape[0] for s in images]\n",
        "  widths_x = [s.shape[1] for s in images]\n",
        "  lengths_y = [len(s) for s in labels]\n",
        "\n",
        "  n_samples = len(heights_x)\n",
        "  max_height_x = np.max(heights_x)\n",
        "  max_width_x = np.max(widths_x)\n",
        "  maxlen_y = np.max(lengths_y) + 1\n",
        "\n",
        "  x = np.zeros((n_samples, max_height_x, max_width_x)).astype('float32')\n",
        "  y =np.zeros((maxlen_y, n_samples)).astype('int64') # the <eol> must be 0 in the dict !!!\n",
        "  x_mask =np.zeros((n_samples, max_height_x, max_width_x)).astype('float32')\n",
        "  y_mask = np.zeros((maxlen_y, n_samples)).astype('float32')\n",
        "\n",
        "  for idx, [s_x, s_y] in enumerate(zip(images, labels)):\n",
        "    x[idx, :heights_x[idx], :widths_x[idx]] =s_x #(s_x-min(s_x.flatten()))/(max(s_x.flatten())-min(s_x.flatten())).\n",
        "    x_flatten=list(chain.from_iterable(x[idx,:,:]))\n",
        "    x[idx,:,:]=(x[idx,:,:]-min(x_flatten))/(max(x_flatten)-min(x_flatten))\n",
        "    x_mask[idx, :heights_x[idx], :widths_x[idx]] = 1.\n",
        "    y[:lengths_y[idx], idx] = s_y\n",
        "    y_mask[:lengths_y[idx], idx] = 1.\n",
        "  return x, x_mask, y, y_mask\n",
        "\n",
        "##  Utility functions used to initialize vaiables\n",
        "def norm_weight(fan_in, fan_out):\n",
        "    W_bound = np.sqrt(6.0 / (fan_in + fan_out))\n",
        "    return np.asarray(rng.uniform(low=-W_bound, high=W_bound, size=(fan_in, fan_out)), dtype=np.float32)\n",
        "\n",
        "def conv_norm_weight(nin, nout, kernel_size):\n",
        "    filter_shape = (kernel_size[0], kernel_size[1], nin, nout)\n",
        "    fan_in = kernel_size[0] * kernel_size[1] * nin\n",
        "    fan_out = kernel_size[0] * kernel_size[1] * nout\n",
        "    W_bound = np.sqrt(6. / (fan_in + fan_out))\n",
        "    W = np.asarray(rng.uniform(low=-W_bound, high=W_bound, size=filter_shape), dtype=np.float32)\n",
        "    return W.astype('float32')\n",
        "\n",
        "def ortho_weight(ndim):\n",
        "    W = np.random.randn(ndim, ndim)\n",
        "    u, s, v = np.linalg.svd(W)\n",
        "    return u.astype('float32')"
      ],
      "metadata": {
        "id": "5sVyA6IGaKsf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##########apply L2 regularization on weights\n",
        "def get_loss(loss,model):\n",
        "    #print(model.trainable_weights)\n",
        "    for layer in model.trainable_weights:\n",
        "      arr=(layer.name).split(\"/\")\n",
        "      if not arr[len(arr)-1].startswith('conv2d'):\n",
        "        loss += lambda_val * tf.reduce_sum(input_tensor=tf.pow(layer, 2))\n",
        "    return loss\n",
        "\n",
        "def cmp_result(label,rec):\n",
        "    dist_mat = np.zeros((len(label)+1, len(rec)+1),dtype='int32')\n",
        "    dist_mat[0,:] = range(len(rec) + 1)\n",
        "    dist_mat[:,0] = range(len(label) + 1)\n",
        "    for i in range(1, len(label) + 1):\n",
        "        for j in range(1, len(rec) + 1):\n",
        "            hit_score = dist_mat[i-1, j-1] + (label[i-1] != rec[j-1])\n",
        "            ins_score = dist_mat[i,j-1] + 1\n",
        "            del_score = dist_mat[i-1, j] + 1\n",
        "            dist_mat[i,j] = min(hit_score, ins_score, del_score)\n",
        "\n",
        "    dist = dist_mat[len(label), len(rec)]\n",
        "    return dist, len(label)\n",
        "def convert(list):\n",
        "\n",
        "    # Converting integer list to string list\n",
        "    s = [str(i) for i in list]\n",
        "\n",
        "    # Join list items using join()\n",
        "    res = \"\".join(s)\n",
        "\n",
        "    return(res)\n",
        "def process_chr_error(rec, label):\n",
        "    rec_mat = rec\n",
        "    label_mat = label\n",
        "    dist, llen = cmp_result(label, rec)\n",
        "    chr_error= float(dist)/llen\n",
        "    return chr_error\n",
        "\n",
        "def process_wer_error(rec, label):\n",
        "    rec=convert(rec)\n",
        "    label=convert(label)\n",
        "    rec_mat = rec.split(\"4\")\n",
        "    label_mat = label.split(\"4\")\n",
        "    dist, llen = cmp_result(label_mat, rec_mat)\n",
        "    wer = float(dist)/llen\n",
        "    return wer\n",
        "def process(rec, label):\n",
        "        cer=process_chr_error(rec, label)\n",
        "        wer=process_wer_error(rec, label)\n",
        "        return cer,wer\n",
        "\n",
        "def load_dict_picklefile(dictFile):\n",
        "    fp=open(dictFile,'rb')\n",
        "    lexicon=pkl.load(fp)\n",
        "    fp.close()\n",
        "    return lexicon,lexicon[' ']"
      ],
      "metadata": {
        "id": "PKP4e9mJaM16"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#### training setup parameters ####\n",
        "\n",
        "#global and hard coded values are there\n",
        "\n",
        "max_label_len=1300\n",
        "#num_classes #it will update dynamically by loading the length of worddict\n",
        "\n",
        "batch_size=2\n",
        "lambda_val=1e-4\n",
        "gamma_val=1\n",
        "dropout_ratio = 0.2\n",
        "dense_block = 3\n",
        "\n",
        "#global parameter for testing\n",
        "beam_width = 10\n",
        "\n",
        "class DenseEncoder(layers.Layer):\n",
        "\tdef __init__(self, blocks,       # number of dense blocks\n",
        "\t\t\t\tlevel,                     # number of levels in each blocks\n",
        "\t\t\t\tgrowth_rate,               # growth rate in DenseNet paper: k\n",
        "\t\t\t\tistraining,\n",
        "\t\t\t\tdropout_rate=0.2,          # keep-rate of dropout layer\n",
        "\t\t\t\tdense_channels=0,          # filter numbers of transition layer's input\n",
        "\t\t\t\ttransition=0.5,            # rate of comprssion\n",
        "\t\t\t\tinput_conv_filters=48,     # filter numbers of conv2d before dense blocks\n",
        "\t\t\t\tinput_conv_stride=(2,2),       # stride of conv2d before dense blocks\n",
        "\t\t\t\tinput_conv_kernel=(7,7), **kwargs):  # kernel size of conv2d before dense blocks\n",
        "\t\tsuper(DenseEncoder, self).__init__( **kwargs)\n",
        "\t\tself.blocks = blocks\n",
        "\t\tself.growth_rate = growth_rate\n",
        "\t\tself.training = istraining\n",
        "\t\tself.dense_channels = dense_channels\n",
        "\t\tself.level = level\n",
        "\t\tself.dropout_rate = dropout_rate\n",
        "\t\tself.transition = transition\n",
        "\t\tself.input_conv_kernel = input_conv_kernel\n",
        "\t\tself.input_conv_stride = input_conv_stride\n",
        "\t\tself.input_conv_filters = input_conv_filters\n",
        "\n",
        "\t\tself.limit = self.bound(1, self.input_conv_filters, self.input_conv_kernel)\n",
        "\t\tself.conv1=tf.keras.layers.Conv2D(filters=self.input_conv_filters, kernel_size=self.input_conv_kernel ,strides=self.input_conv_stride, padding='same', data_format='channels_last', use_bias=False , kernel_initializer=tf.random_uniform_initializer(-self.limit, self.limit))\n",
        "\t\tself.batch_norm=tf.keras.layers.BatchNormalization(trainable=self.training, momentum=0.9, scale=True, gamma_initializer=tf.random_uniform_initializer(-1.0/math.sqrt(self.input_conv_filters),1.0/math.sqrt(self.input_conv_filters)), epsilon=0.0001)\n",
        "\t\tself.relu=tf.keras.layers.ReLU()\n",
        "\t\tself.maxpool=tf.keras.layers.MaxPool2D(pool_size=(2, 2), strides=(2, 2), padding='same')\n",
        "\n",
        "\t\tself.dropout=tf.keras.layers.Dropout(rate=self.dropout_rate)\n",
        "\t\tself.avgpool=tf.keras.layers.AveragePooling2D(pool_size=(2, 2), strides=(2, 2), padding='same')\n",
        "\n",
        "\t\tself.conv=[]\n",
        "\t\tself.conv2=[]\n",
        "\t\tself.batchnorm=[]\n",
        "\t\tself.batchnorm2=[]\n",
        "\t\tself.dense_channels += self.input_conv_filters\n",
        "\t\tfor i in range(self.blocks):\n",
        "\t\t\tfor j in range(self.level):\n",
        "\t\t\t\t\tlimit = self.bound(self.dense_channels, 4 * self.growth_rate, [1,1])\n",
        "\t\t\t\t\tself.conv.append(tf.keras.layers.Conv2D(filters=4 * self.growth_rate, kernel_size=(1,1) ,strides=(1,1), padding='valid', data_format='channels_last', use_bias=False , kernel_initializer=tf.random_uniform_initializer(-limit, limit)))\n",
        "\t\t\t\t\tself.batchnorm.append(tf.keras.layers.BatchNormalization(trainable=self.training, momentum=0.9, scale=True,gamma_initializer=tf.random_uniform_initializer(-1.0/math.sqrt(4 * self.growth_rate),1.0/math.sqrt(4 * self.growth_rate)), epsilon=0.0001))\n",
        "\n",
        "\t\t\t\t\tlimit = self.bound(4 * self.growth_rate, self.growth_rate, [3,3])\n",
        "\t\t\t\t\tself.conv.append(tf.keras.layers.Conv2D(filters=self.growth_rate, kernel_size=(3,3) ,strides=(1,1), padding='same', data_format='channels_last', use_bias=False , kernel_initializer=tf.random_uniform_initializer(-limit, limit)))\n",
        "\t\t\t\t\tself.batchnorm.append(tf.keras.layers.BatchNormalization(trainable=self.training, momentum=0.9, scale=True,gamma_initializer=tf.random_uniform_initializer(-1.0/math.sqrt(self.growth_rate),1.0/math.sqrt(self.growth_rate)), epsilon=0.0001))\n",
        "\t\t\t\t\tself.dense_channels += self.growth_rate\n",
        "\n",
        "\t\t\tif i < self.blocks - 1:\n",
        "\t\t\t\t\tcompressed_channels = int(self.dense_channels * self.transition)\n",
        "\n",
        "\t\t\t\t\t#### new dense channels for new dense block ####\n",
        "\t\t\t\t\tself.dense_channels = compressed_channels\n",
        "\t\t\t\t\tlimit = self.bound(self.dense_channels, compressed_channels, [1,1])\n",
        "\t\t\t\t\tself.conv2.append(tf.keras.layers.Conv2D(compressed_channels, kernel_size=(1,1) ,strides=(1,1), padding='valid', data_format='channels_last', use_bias=False , activation=None, kernel_initializer=tf.random_uniform_initializer(-limit, limit)))\n",
        "\t\t\t\t\tself.batchnorm2.append(tf.keras.layers.BatchNormalization(trainable=self.training, momentum=0.9, scale=True, gamma_initializer=tf.random_uniform_initializer(-1.0/math.sqrt(self.dense_channels),1.0/math.sqrt(self.dense_channels)), epsilon=0.0001))\n",
        "\n",
        "\n",
        "\tdef bound(self, nin, nout, kernel):\n",
        "\t\tfin = nin * kernel[0] * kernel[1]\n",
        "\t\tfout = nout * kernel[0] * kernel[1]\n",
        "\t\treturn np.sqrt(6. / (fin + fout))\n",
        "\n",
        "\tdef dense_net(self, input_x, mask_x):\n",
        "\n",
        "\t\t#### before flowing into dense blocks ####\n",
        "\t\tinput_x=tf.expand_dims(input=input_x, axis=3)\n",
        "\t\tx = input_x\n",
        "\t\t#limit = self.bound(1, self.input_conv_filters, self.input_conv_kernel)\n",
        "\t\tx =self.conv1(x)\n",
        "\t\tmask_x = mask_x[:, 0::2, 0::2]\n",
        "\t\tx =self.batch_norm(x)\n",
        "\t\tx =self.relu(x)\n",
        "\t\tx=self.maxpool(x)\n",
        "\t\tinput_pre = x\n",
        "\t\tmask_x = mask_x[:, 0::2, 0::2]\n",
        "\t\tdense_out = x\n",
        "\n",
        "\t\tcind=0\n",
        "\t\tbind=0\n",
        "\t\tcind2=0\n",
        "\t\tbind2=0\n",
        "\t\t#### flowing into dense blocks and transition_layer ####\n",
        "\t\tfor i in range(self.blocks):\n",
        "\t\t\tfor j in range(self.level):\n",
        "\t\t\t\t#### [1, 1] convolution part for bottleneck ####\n",
        "\t\t\t\tx =self.conv[cind](x)\n",
        "\t\t\t\tcind += 1\n",
        "\t\t\t\tx =self.batchnorm[bind](x)\n",
        "\t\t\t\tbind += 1\n",
        "\t\t\t\tx =self.relu(x)\n",
        "\t\t\t\tx =self.dropout(x,training=self.training)\n",
        "\n",
        "\t\t\t\t#### [3, 3] convolution part for regular convolve operation\n",
        "\t\t\t\tx =self.conv[cind](x)\n",
        "\t\t\t\tcind += 1\n",
        "\t\t\t\tx =self.batchnorm[bind](x)\n",
        "\t\t\t\tbind += 1\n",
        "\t\t\t\tx =self.relu(x)\n",
        "\t\t\t\tx =self.dropout(x,training=self.training)\n",
        "\t\t\t\tdense_out = tf.concat([dense_out, x], axis=3)\n",
        "\t\t\t\tx = dense_out\n",
        "\t\t\t\t#### calculate the filter number of dense block's output ####\n",
        "\n",
        "\t\t\tif i < self.blocks - 1:\n",
        "\t\t\t\t#### new dense channels for new dense block ####\n",
        "\t\t\t\tx =self.conv2[cind2](x)\n",
        "\t\t\t\tcind2 += 1\n",
        "\t\t\t\tx =self.batchnorm2[bind2](x)\n",
        "\t\t\t\tbind2 += 1\n",
        "\t\t\t\tx =self.relu(x)\n",
        "\t\t\t\tx =self.dropout(x,training=self.training)\n",
        "\t\t\t\tx=self.avgpool(x)\n",
        "\t\t\t\tdense_out = x\n",
        "\t\t\t\tmask_x = mask_x[:, 0::2, 0::2]\n",
        "\n",
        "\t\treturn dense_out, mask_x\n",
        "\n",
        "\n",
        "'''\n",
        "ContextualAttention class implements contextual attention mechanism.\n",
        "'''\n",
        "class ContextualAttention(layers.Layer):\n",
        "\tdef __init__(self, channels,                          # output of DenseEncoder | [batch, h, w, channels]\n",
        "\t\t\t\tdim_decoder, dim_attend, **kwargs):                       # decoder hidden state:$h_{t-1}$ | [batch, dec_dim]\n",
        "\t\tsuper(ContextualAttention, self).__init__( **kwargs)\n",
        "\t\tself.channels = channels\n",
        "\n",
        "\t\tself.coverage_kernel = [11,11]                      # kernel size of $Q$\n",
        "\t\tself.coverage_filters = dim_attend                  # filter numbers of $Q$ | 512\n",
        "\n",
        "\t\tself.dim_decoder = dim_decoder                      # 256\n",
        "\t\tself.dim_attend = dim_attend                        # unified dim of three parts calculating $e_ti$ i.e.\n",
        "\t\t                                                    # $Q*beta_t$, $U_a * a_i$, $W_a x h_{t-1}$ | 512\n",
        "\t\tself.U_f = tf.Variable(norm_weight(self.coverage_filters, self.dim_attend), name='U_f') # $U_f x f_i$ | [cov_filters, dim_attend]\n",
        "\t\tself.U_f_b = tf.Variable(np.zeros((self.dim_attend,)).astype('float32'), name='U_f_b')  # $U_f x f_i + U_f_b$ | [dim_attend, ]\n",
        "\n",
        "\t\tself.U_a = tf.Variable(norm_weight(self.channels,self.dim_attend), name='U_a')         # $U_a x a_i$ | [annotatin_channels, dim_attend]\n",
        "\t\tself.U_a_b = tf.Variable(np.zeros((self.dim_attend,)).astype('float32'), name='U_a_b') # $U_a x a_i + U_a_b$ | [dim_attend, ]\n",
        "\n",
        "\t\tself.W_a = tf.Variable(norm_weight(self.dim_decoder,self.dim_attend), name='W_a')      # $W_a x h_{t_1}$ | [dec_dim, dim_attend]\n",
        "\t\tself.W_a_b = tf.Variable(np.zeros((self.dim_attend,)).astype('float32'), name='W_a_b') # $W_a x h_{t-1} + W_a_b$ | [dim_attend, ]\n",
        "\n",
        "\t\tself.V_a = tf.Variable(norm_weight(self.dim_attend, 1), name='V_a')                    # $V_a x tanh(A + B + C)$ | [dim_attend, 1]\n",
        "\t\tself.V_a_b = tf.Variable(np.zeros((1,)).astype('float32'), name='V_a_b')               # $V_a x tanh(A + B + C) + V_a_b$ | [1, ]\n",
        "\n",
        "\t\tself.alpha_past_filter = tf.Variable(conv_norm_weight(1, self.dim_attend, self.coverage_kernel), name='alpha_past_filter')\n",
        "\n",
        "\n",
        "\tdef get_context(self, annotation4ctx, h_t_1, alpha_past4ctx, a_mask):\n",
        "\n",
        "\t\t#### calculate $U_f x f_i$ ####\n",
        "\t\talpha_past_4d = alpha_past4ctx[:, :, :, None]\n",
        "\n",
        "\t\tFt = tf.nn.conv2d(alpha_past_4d, filters=self.alpha_past_filter, strides=[1, 1, 1, 1], padding='SAME')\n",
        "\t\tcoverage_vector = tf.tensordot(Ft, self.U_f, axes=1) \t#+ self.U_f_b    # [batch, h, w, dim_attend]\n",
        "\n",
        "\t\t#### calculate $U_a x a_i$ ####\n",
        "\t\tdense_encoder_vector = tf.tensordot(annotation4ctx, self.U_a, axes=1) #+ self.U_a_b   # [batch, h, w, dim_attend]\n",
        "\n",
        "\t\t#### calculate $W_a x h_{t - 1}$ ####\n",
        "\t\tspeller_vector = tf.tensordot(h_t_1, self.W_a, axes=1) #+ self.W_a_b   # [batch, dim_attend]\n",
        "\t\tspeller_vector = speller_vector[:, None, None, :]    # [batch, None, None, dim_attend]\n",
        "\n",
        "\t\ttanh_vector = tf.tanh(coverage_vector + dense_encoder_vector + speller_vector + self.U_f_b)    # [batch, h, w, dim_attend]\n",
        "\t\te_ti = tf.tensordot(tanh_vector, self.V_a, axes=1) + self.V_a_b  # [batch, h, w, 1]\n",
        "\t\talpha = tf.exp(e_ti)\n",
        "\t\talpha = tf.squeeze(alpha, axis=3)\n",
        "\n",
        "\t\tif a_mask is not None:\n",
        "\t\t\talpha = alpha * a_mask\n",
        "\n",
        "\t\talpha = alpha / tf.reduce_sum(alpha, axis=[1, 2], keepdims=True)    # normlized weights | [batch, h, w]\n",
        "\t\talpha_past4ctx += alpha    # accumalated weights matrix | [batch, h, w]\n",
        "\t\tcontext = tf.reduce_sum(annotation4ctx * alpha[:, :, :, None], axis=[1, 2])   # context vector | [batch, feature_channels]\n",
        "\t\treturn context, alpha, alpha_past4ctx\n",
        "\n",
        "'''\n",
        "Decoder class implements 2 layerd Decoder (GRU) which decodes an input image\n",
        "and outputs a seuence of characters using attention mechanism .\n",
        "'''\n",
        "class Decoder(layers.Layer):\n",
        "    def __init__(self, hidden_dim, word_dim, contextual_attention, context_dim, **kwargs):\n",
        "        super(Decoder, self).__init__(**kwargs)\n",
        "        self.contextual_attention = contextual_attention                                # inner-instance of contextual_attention to provide context\n",
        "        self.context_dim = context_dim                          # context dim 684\n",
        "        self.hidden_dim = hidden_dim                            # dim of hidden state  256\n",
        "        self.word_dim = word_dim                                # dim of embedding word 256\n",
        "\n",
        "        ##GRU 1 weights initialization starts here\n",
        "        self.W_yz_yr = tf.Variable(np.concatenate(\n",
        "            [norm_weight(self.word_dim, self.hidden_dim), norm_weight(self.word_dim, self.hidden_dim)], axis=1), name='W_yz_yr') # [dim_word, 2 * dim_decoder]\n",
        "        self.b_yz_yr = tf.Variable(np.zeros((2 * self.hidden_dim, )).astype('float32'), name='b_yz_yr')\n",
        "\n",
        "        self.U_hz_hr = tf.Variable(np.concatenate(\n",
        "            [ortho_weight(self.hidden_dim), ortho_weight(self.hidden_dim)], axis=1), name='U_hz_hr')                              # [dim_hidden, 2 * dim_hidden]\n",
        "\n",
        "        self.W_yh = tf.Variable(norm_weight(self.word_dim,\n",
        "            self.hidden_dim), name='W_yh')\n",
        "        self.b_yh = tf.Variable(np.zeros((self.hidden_dim, )).astype('float32'), name='b_yh')                                    # [dim_decoder, ]\n",
        "\n",
        "        self.U_rh = tf.Variable(ortho_weight(self.hidden_dim), name='U_rh')                                                      # [dim_hidden, dim_hidden]\n",
        "\n",
        "        ##GRU 2 weights initialization starts here\n",
        "        self.U_hz_hr_nl = tf.Variable(np.concatenate(\n",
        "            [ortho_weight(self.hidden_dim), ortho_weight(self.hidden_dim)], axis=1), name='U_hz_hr_nl')                          # [dim_hidden, 2 * dim_hidden] non_linear\n",
        "\n",
        "        self.b_hz_hr_nl = tf.Variable(np.zeros((2 * self.hidden_dim, )).astype('float32'), name='b_hz_hr_nl')                    # [2 * dim_hidden, ]\n",
        "\n",
        "        self.W_c_z_r = tf.Variable(norm_weight(self.context_dim,\n",
        "            2 * self.hidden_dim), name='W_c_z_r')\n",
        "\n",
        "        self.U_rh_nl = tf.Variable(ortho_weight(self.hidden_dim), name='U_rh_nl')\n",
        "        self.b_rh_nl = tf.Variable(np.zeros((self.hidden_dim, )).astype('float32'), name='b_rh_nl')\n",
        "\n",
        "        self.W_c_h_nl = tf.Variable(norm_weight(self.context_dim, self.hidden_dim), name='W_c_h_nl')\n",
        "\n",
        "    def get_ht_ctx(self, emb_y, target_hidden_state_0, annotations, a_m, y_m):\n",
        "\n",
        "        res = tf.scan(self.one_time_step, elems=(emb_y, y_m),\n",
        "            initializer=(target_hidden_state_0,\n",
        "                tf.zeros([tf.shape(annotations)[0], self.context_dim]),\n",
        "                tf.zeros([tf.shape(annotations)[0], tf.shape(annotations)[1], tf.shape(annotations)[2]]),\n",
        "                tf.zeros([tf.shape(annotations)[0], tf.shape(annotations)[1], tf.shape(annotations)[2]]),\n",
        "                annotations, a_m))\n",
        "\n",
        "        return res\n",
        "\n",
        "    def one_time_step(self, tuple_h0_ctx_alpha_alpha_past_annotation, tuple_emb_mask):\n",
        "\n",
        "        target_hidden_state_0 = tuple_h0_ctx_alpha_alpha_past_annotation[0]\n",
        "        alpha_past_one        = tuple_h0_ctx_alpha_alpha_past_annotation[3]\n",
        "        annotation_one        = tuple_h0_ctx_alpha_alpha_past_annotation[4]\n",
        "        a_mask                = tuple_h0_ctx_alpha_alpha_past_annotation[5]\n",
        "\n",
        "        emb_y, y_mask = tuple_emb_mask\n",
        "\n",
        "        # GRU 1 starts here\n",
        "        emb_y_z_r_vector = tf.tensordot(emb_y, self.W_yz_yr, axes=1) + self.b_yz_yr                                            # [batch, 2 * dim_decoder]\n",
        "        hidden_z_r_vector = tf.tensordot(target_hidden_state_0, self.U_hz_hr, axes=1)                                         # [batch, 2 * dim_decoder]\n",
        "        pre_z_r_vector = tf.sigmoid(emb_y_z_r_vector + hidden_z_r_vector)                                                    # [batch, 2 * dim_decoder]\n",
        "\n",
        "        r1 = pre_z_r_vector[:, :self.hidden_dim]                # [batch, dim_decoder]\n",
        "        z1 = pre_z_r_vector[:, self.hidden_dim:]                # [batch, dim_decoder]\n",
        "\n",
        "        emb_y_h_vector = tf.tensordot(emb_y, self.W_yh, axes=1) + self.b_yh                                               # [batch, dim_decoder]\n",
        "        hidden_r_h_vector = tf.tensordot(target_hidden_state_0, self.U_rh, axes=1)                                      # [batch, dim_decoder]\n",
        "        hidden_r_h_vector *= r1\n",
        "        pre_h_proposal = tf.tanh(hidden_r_h_vector + emb_y_h_vector)\n",
        "\n",
        "        pre_h = z1 * target_hidden_state_0 + (1. - z1) * pre_h_proposal\n",
        "\n",
        "        if y_mask is not None:\n",
        "            pre_h = y_mask[:, None] * pre_h + (1. - y_mask)[:, None] * target_hidden_state_0\n",
        "\n",
        "        context, alpha, alpha_past_one = self.contextual_attention.get_context(annotation_one, pre_h, alpha_past_one, a_mask)  # [batch, dim_ctx]\n",
        "\n",
        "        # GRU 2 starts here\n",
        "        emb_y_z_r_nl_vector = tf.tensordot(pre_h, self.U_hz_hr_nl, axes=1) + self.b_hz_hr_nl\n",
        "        context_z_r_vector = tf.tensordot(context, self.W_c_z_r, axes=1)\n",
        "        z_r_vector = tf.sigmoid(emb_y_z_r_nl_vector + context_z_r_vector)\n",
        "\n",
        "        r2 = z_r_vector[:, :self.hidden_dim]\n",
        "        z2 = z_r_vector[:, self.hidden_dim:]\n",
        "\n",
        "        emb_y_h_nl_vector = tf.tensordot(pre_h, self.U_rh_nl, axes=1)\n",
        "        emb_y_h_nl_vector *= r2\n",
        "        emb_y_h_nl_vector = emb_y_h_nl_vector + self.b_rh_nl # bias added after pointwise multiplication with r2\n",
        "        context_h_vector = tf.tensordot(context, self.W_c_h_nl, axes=1)\n",
        "        h_proposal = tf.tanh(emb_y_h_nl_vector + context_h_vector)\n",
        "        h = z2 * pre_h + (1. - z2) * h_proposal\n",
        "\n",
        "        if y_mask is not None:\n",
        "            h = y_mask[:, None] * h + (1. - y_mask)[:, None] * pre_h\n",
        "\n",
        "        return h, context, alpha, alpha_past_one, annotation_one, a_mask\n",
        "\n",
        "\n",
        "'''\n",
        "CALText class is the main class. This class uses below three classes:\n",
        "1) DenseEncoder (Encoder)\n",
        "2) ContextualAttention (Contextual attention mechnism)\n",
        "3) Decoder (2 layerd GRU Decoder)\n",
        "CALText class implements two functions get_cost and get_sample, which are actually used for cost calculation and decoding.\n",
        "'''\n",
        "class CALText(layers.Layer):\n",
        "\tdef __init__(self, dense_encoder, contextual_attention, decoder, hidden_dim, word_dim, context_dim, target_dim, istraining,**kwargs):\n",
        "\t\tsuper(CALText, self).__init__( **kwargs)\n",
        "\t\t#self.batch_size = batch_size\n",
        "\t\tself.hidden_dim = hidden_dim\n",
        "\t\tself.word_dim = word_dim\n",
        "\t\tself.context_dim = context_dim\n",
        "\t\tself.target_dim = target_dim\n",
        "\t\tself.embed_matrix = tf.Variable(norm_weight(self.target_dim, self.word_dim), name='embed')\n",
        "\n",
        "\t\tself.dense_encoder = dense_encoder\n",
        "\t\tself.contextual_attention = contextual_attention\n",
        "\t\tself.decoder = decoder\n",
        "\t\tself.Wa2h = tf.Variable(norm_weight(self.context_dim, self.hidden_dim), name='Wa2h')\n",
        "\t\tself.ba2h = tf.Variable(np.zeros((self.hidden_dim,)).astype('float32'), name='ba2h')\n",
        "\t\tself.Wc = tf.Variable(norm_weight(self.context_dim, self.word_dim), name='Wc')\n",
        "\t\tself.bc = tf.Variable(np.zeros((self.word_dim,)).astype('float32'), name='bc')\n",
        "\t\tself.Wh = tf.Variable(norm_weight(self.hidden_dim, self.word_dim), name='Wh')\n",
        "\t\tself.bh = tf.Variable(np.zeros((self.word_dim,)).astype('float32'), name='bh')\n",
        "\t\tself.Wy = tf.Variable(norm_weight(self.word_dim, self.word_dim), name='Wy')\n",
        "\t\tself.by = tf.Variable(np.zeros((self.word_dim,)).astype('float32'), name='by')\n",
        "\t\tself.Wo = tf.Variable(norm_weight(self.word_dim//2, self.target_dim), name='Wo')\n",
        "\t\tself.bo = tf.Variable(np.zeros((self.target_dim,)).astype('float32'), name='bo')\n",
        "\t\tself.training = istraining\n",
        "\t\tself.dropout=tf.keras.layers.Dropout(rate=0.2)\n",
        "\n",
        "\n",
        "\tdef get_cost(self, cost_annotation, cost_y, a_m, y_m,gamma):\n",
        "\n",
        "\t\t#### step: 1 prepration of embedding of labels sequences ####\n",
        "\t\ttimesteps = tf.shape(cost_y)[0]\n",
        "\t\tbatch_size = tf.shape(cost_y)[1]\n",
        "\n",
        "\t\temb_y = tf.nn.embedding_lookup(self.embed_matrix, tf.reshape(cost_y, [-1]))\n",
        "\t\temb_y = tf.reshape(emb_y, [timesteps, batch_size, self.word_dim])\n",
        "\t\temb_pad = tf.fill((1, batch_size, self.word_dim), 0.0)\n",
        "\t\temb_shift = tf.concat([emb_pad ,tf.strided_slice(emb_y, [0, 0, 0], [-1, batch_size, self.word_dim], [1, 1, 1])], axis=0)\n",
        "\t\tnew_emb_y = emb_shift\n",
        "\n",
        "\t\t#### step: 2 calculation of h_0 ####\n",
        "\t\tanno_mean = tf.reduce_sum(cost_annotation * a_m[:, :, :, None], axis=[1, 2]) / tf.reduce_sum(a_m, axis=[1, 2])[:, None]\n",
        "\t\th_0 = tf.tensordot(anno_mean, self.Wa2h, axes=1) + self.ba2h  # [batch, hidden_dim]\n",
        "\t\th_0 = tf.tanh(h_0)\n",
        "\n",
        "\t\t#### step: 3 calculation of h_t and c_t at all time steps ####\n",
        "\t\tret = self.decoder.get_ht_ctx(new_emb_y, h_0, cost_annotation, a_m, y_m)\n",
        "\t\th_t = ret[0]                      # h_t of all timesteps [timesteps, batch, hidden_dim]\n",
        "\t\tc_t = ret[1]                      # c_t of all timesteps [timesteps, batch, context_dim]\n",
        "\t\talpha=ret[2]\t\t\t\t\t\t\t\t\t\t\t# alpha of all timesteps [timesteps, batch, h, w]\n",
        "\n",
        "\t\t#### step: 4 calculation of cost using h_t, c_t and y_t_1 ####\n",
        "\t\ty_t_1 = new_emb_y                 # shifted y | [1:] = [:-1]\n",
        "\t\tlogit_gru = tf.tensordot(h_t, self.Wh, axes=1) #+ self.bh\n",
        "\t\tlogit_ctx = tf.tensordot(c_t, self.Wc, axes=1) #+ self.bc\n",
        "\t\tlogit_pre = tf.tensordot(y_t_1, self.Wy, axes=1) #+ self.by\n",
        "\t\tlogit = logit_pre + logit_ctx + logit_gru + self.bh\n",
        "\t\tshape = tf.shape(logit)\n",
        "\t\tlogit = tf.reshape(logit, [shape[0], -1, shape[2]//2, 2])\n",
        "\t\tlogit = tf.reduce_max(logit, axis=3)\n",
        "\t\tlogit =self.dropout(logit,training=self.training)\n",
        "\t\t#logit = tf.layers.dropout(inputs=logit, rate=0.2, training=self.training)\n",
        "\n",
        "\t\tlogit = tf.tensordot(logit, self.Wo, axes=1) + self.bo\n",
        "\t\tlogit_shape = tf.shape(logit)\n",
        "\t\tlogit = tf.reshape(logit, [-1,logit_shape[2]])\n",
        "\t\tcost = tf.nn.softmax_cross_entropy_with_logits(logits=logit, labels=tf.one_hot(tf.reshape(cost_y, [-1]),depth=self.target_dim))\n",
        "\n",
        "\t\t#### max pooling on vector with size equal to word_dim ####\n",
        "\t\tcost = tf.multiply(cost, tf.reshape(y_m, [-1]))\n",
        "\t\tcost = tf.reshape(cost, [shape[0], shape[1]])\n",
        "\t\tcost = tf.reduce_sum(cost, axis=0)\n",
        "\t\tcost = tf.reduce_mean(cost)\n",
        "\n",
        "\t\t#### alpha  L1 regularization ####\n",
        "\t\talpha_sum=tf.reduce_mean(tf.reduce_sum(tf.reduce_sum(tf.abs(alpha), axis=[2, 3]),axis=0))\n",
        "\t\tcost = tf.cond(tf.cast(gamma > 0, tf.bool),  \tlambda: cost + (gamma * alpha_sum), lambda: cost)\n",
        "\n",
        "\t\tcost=get_loss(cost,model)#apply L2 regularization on weights\n",
        "\n",
        "\t\treturn cost\n",
        "\n",
        "\n",
        "\tdef get_word(self, sample_y, sample_h_pre, alpha_past_pre, sample_annotation,training_mode):\n",
        "\n",
        "\t\temb = tf.cond(pred=sample_y[0] < 0,\n",
        "\t\t\ttrue_fn=lambda: tf.fill((1, self.word_dim), 0.0),\n",
        "\t\t\tfalse_fn=lambda: tf.nn.embedding_lookup(params=self.embed_matrix, ids=sample_y)\n",
        "\t\t\t)\n",
        "\n",
        "\t\t#ret = self.decoder.one_time_step((h_pre, None, None, alpha_past_pre, annotation, None), (emb, None))\n",
        "\t\temb_y_z_r_vector = tf.tensordot(emb, self.decoder.W_yz_yr, axes=1) + \\\n",
        "\t\tself.decoder.b_yz_yr                                            # [batch, 2 * dim_decoder]\n",
        "\t\thidden_z_r_vector = tf.tensordot(sample_h_pre,\n",
        "\t\tself.decoder.U_hz_hr, axes=1)                                   # [batch, 2 * dim_decoder]\n",
        "\t\tpre_z_r_vector = tf.sigmoid(emb_y_z_r_vector + \\\n",
        "\t\thidden_z_r_vector)                                             # [batch, 2 * dim_decoder]\n",
        "\n",
        "\t\tr1 = pre_z_r_vector[:, :self.decoder.hidden_dim]                # [batch, dim_decoder]\n",
        "\t\tz1 = pre_z_r_vector[:, self.decoder.hidden_dim:]                # [batch, dim_decoder]\n",
        "\n",
        "\t\temb_y_h_vector = tf.tensordot(emb, self.decoder.W_yh, axes=1) + \\\n",
        "\t\tself.decoder.b_yh                                               # [batch, dim_decoder]\n",
        "\t\thidden_r_h_vector = tf.tensordot(sample_h_pre,\n",
        "\t\tself.decoder.U_rh, axes=1)                                      # [batch, dim_decoder]\n",
        "\t\thidden_r_h_vector *= r1\n",
        "\t\tpre_h_proposal = tf.tanh(hidden_r_h_vector + emb_y_h_vector)\n",
        "\n",
        "\t\tpre_h = z1 * sample_h_pre + (1. - z1) * pre_h_proposal\n",
        "\n",
        "\t\tcontext, alphacc, alpha_past = self.decoder.contextual_attention.get_context(sample_annotation, pre_h, alpha_past_pre, None)  # [batch, dim_ctx]\n",
        "\t\temb_y_z_r_nl_vector = tf.tensordot(pre_h, self.decoder.U_hz_hr_nl, axes=1) + self.decoder.b_hz_hr_nl\n",
        "\t\tcontext_z_r_vector = tf.tensordot(context, self.decoder.W_c_z_r, axes=1)\n",
        "\t\tz_r_vector = tf.sigmoid(emb_y_z_r_nl_vector + context_z_r_vector)\n",
        "\n",
        "\t\tr2 = z_r_vector[:, :self.decoder.hidden_dim]\n",
        "\t\tz2 = z_r_vector[:, self.decoder.hidden_dim:]\n",
        "\n",
        "\t\temb_y_h_nl_vector = tf.tensordot(pre_h, self.decoder.U_rh_nl, axes=1) + self.decoder.b_rh_nl\n",
        "\t\temb_y_h_nl_vector *= r2\n",
        "\t\tcontext_h_vector = tf.tensordot(context, self.decoder.W_c_h_nl, axes=1)\n",
        "\t\th_proposal = tf.tanh(emb_y_h_nl_vector + context_h_vector)\n",
        "\t\th = z2 * pre_h + (1. - z2) * h_proposal\n",
        "\n",
        "\t\th_t = h\n",
        "\t\tc_t = context\n",
        "\t\talpha_past_t = alpha_past\n",
        "\t\ty_t_1 = emb\n",
        "\t\tlogit_gru = tf.tensordot(h_t, self.Wh, axes=1) #+ self.bh\n",
        "\t\tlogit_ctx = tf.tensordot(c_t, self.Wc, axes=1) #+ self.bc\n",
        "\t\tlogit_pre = tf.tensordot(y_t_1, self.Wy, axes=1) #+ self.by\n",
        "\t\tlogit = logit_pre + logit_ctx + logit_gru  + self.bh # batch x word_dim\n",
        "\n",
        "\t\tshape = tf.shape(input=logit)\n",
        "\t\tlogit = tf.reshape(logit, [-1, shape[1]//2, 2])\n",
        "\t\tlogit = tf.reduce_max(input_tensor=logit, axis=2)\n",
        "\n",
        "\t\tlogit =  self.dropout(logit,training=training_mode)\n",
        "\n",
        "\t\tlogit = tf.tensordot(logit, self.Wo, axes=1) + self.bo\n",
        "\n",
        "\t\tnext_probs = tf.nn.softmax(logits=logit)\n",
        "\t\tnext_word  = tf.reduce_max(input_tensor=tf.random.categorical(logits=next_probs, num_samples=1), axis=1)\n",
        "\t\treturn next_probs, next_word, h_t, alpha_past_t, alphacc\n",
        "\n",
        "@tf.function(experimental_relax_shapes=True)\n",
        "def get_word(next_w, next_state, next_alpha_past, ctx, model,training):\n",
        "   return model.caltext.get_word(next_w, next_state, next_alpha_past, ctx,training)\n",
        "\n",
        "def get_sample(ctx0, h_0, k , maxlen, stochastic, training, model):\n",
        "\n",
        "\t\tsample = []\n",
        "\t\tsample_score = []\n",
        "\t\tsample_att=[]\n",
        "\t\tlive_k = 1\n",
        "\t\tdead_k = 0\n",
        "\n",
        "\t\thyp_samples = [[]] * 1\n",
        "\t\thyp_scores = np.zeros(live_k).astype('float32')\n",
        "\t\thyp_states = []\n",
        "\n",
        "\n",
        "\t\tnext_alpha_past = np.zeros((ctx0.shape[0], ctx0.shape[1], ctx0.shape[2])).astype('float32')\n",
        "\t\temb_0 = np.zeros((ctx0.shape[0], 256))\n",
        "\n",
        "\t\tnext_w = -1 * np.ones((1,)).astype('int64')\n",
        "\n",
        "\t\tnext_state = h_0\n",
        "\t\t#tf.autograph.experimental.set_loop_options(shape_invariants=[(next_alpha_past, tf.TensorShape([None]))])\n",
        "\n",
        "\t\tfor ii in range(maxlen):\n",
        "\n",
        "\t\t\tctx = np.tile(ctx0, [live_k, 1, 1, 1])\n",
        "\t\t\tnext_p, next_w, next_state, next_alpha_past,contexVec  = get_word(next_w, next_state, next_alpha_past, ctx, model,training)\n",
        "\t\t\tsample_att.append(contexVec[0,:,:])\n",
        "\t\t\tif stochastic:\n",
        "\t\t\t\tnw = next_w[0]\n",
        "\t\t\t\tsample.append(nw)\n",
        "\t\t\t\tsample_score += next_p[0, nw]\n",
        "\t\t\t\tif nw == 0:\n",
        "\t\t\t\t\tbreak\n",
        "\t\t\telse:\n",
        "\n",
        "\t\t\t\tcand_scores = hyp_scores[:, None] - np.log(next_p)\n",
        "\t\t\t\tcand_flat = cand_scores.flatten()\n",
        "\t\t\t\tranks_flat = cand_flat.argsort()[:(k-dead_k)]\n",
        "\t\t\t\tvoc_size = next_p.shape[1]\n",
        "\n",
        "\t\t\t\tassert voc_size==num_classes\n",
        "\n",
        "\t\t\t\ttrans_indices = ranks_flat // voc_size\n",
        "\t\t\t\tword_indices = ranks_flat % voc_size\n",
        "\t\t\t\tcosts = cand_flat[ranks_flat]\n",
        "\t\t\t\tnew_hyp_samples = []\n",
        "\t\t\t\tnew_hyp_scores = np.zeros(k-dead_k).astype('float32')\n",
        "\t\t\t\tnew_hyp_states = []\n",
        "\t\t\t\tnew_hyp_alpha_past = []\n",
        "\n",
        "\t\t\t\tfor idx, [ti, wi] in enumerate(zip(trans_indices, word_indices)):\n",
        "\t\t\t\t\tnew_hyp_samples.append(hyp_samples[ti]+[wi])\n",
        "\t\t\t\t\tnew_hyp_scores[idx] = copy.copy(costs[idx])\n",
        "\t\t\t\t\tnew_hyp_states.append(copy.copy(next_state[ti]))\n",
        "\t\t\t\t\tnew_hyp_alpha_past.append(copy.copy(next_alpha_past[ti]))\n",
        "\n",
        "\t\t\t\tnew_live_k = 0\n",
        "\t\t\t\thyp_samples = []\n",
        "\t\t\t\thyp_scores = []\n",
        "\t\t\t\thyp_states = []\n",
        "\t\t\t\thyp_alpha_past = []\n",
        "\n",
        "\t\t\t\tfor idx in range(len(new_hyp_samples)):\n",
        "\t\t\t\t\tif new_hyp_samples[idx][-1] == 0: # <eol>\n",
        "\t\t\t\t\t\tsample.append(new_hyp_samples[idx])\n",
        "\t\t\t\t\t\tsample_score.append(new_hyp_scores[idx])\n",
        "\t\t\t\t\t\tdead_k += 1\n",
        "\t\t\t\t\telse:\n",
        "\t\t\t\t\t\tnew_live_k += 1\n",
        "\t\t\t\t\t\thyp_samples.append(new_hyp_samples[idx])\n",
        "\t\t\t\t\t\thyp_scores.append(new_hyp_scores[idx])\n",
        "\t\t\t\t\t\thyp_states.append(new_hyp_states[idx])\n",
        "\t\t\t\t\t\thyp_alpha_past.append(new_hyp_alpha_past[idx])\n",
        "\t\t\t\thyp_scores = np.array(hyp_scores)\n",
        "\t\t\t\tlive_k = new_live_k\n",
        "\n",
        "\t\t\t\tif new_live_k < 1:\n",
        "\t\t\t\t\tbreak\n",
        "\t\t\t\tif dead_k >= k:\n",
        "\t\t\t\t\tbreak\n",
        "\n",
        "\t\t\t\tnext_w = np.array([w1[-1] for w1 in hyp_samples])\n",
        "\t\t\t\tnext_state = np.array(hyp_states)\n",
        "\t\t\t\tnext_alpha_past = np.array(hyp_alpha_past)\n",
        "\n",
        "\t\tif not stochastic:\n",
        "\t\t\t# dump every remaining one\n",
        "\t\t\tif live_k > 0:\n",
        "\t\t\t\tfor idx in range(live_k):\n",
        "\t\t\t\t\tsample.append(hyp_samples[idx])\n",
        "\t\t\t\t\tsample_score.append(hyp_scores[idx])\n",
        "\n",
        "\t\treturn sample, sample_score,sample_att\n",
        "\n",
        "\n",
        "class CALTEXT_Model(tf.keras.Model): # Subclass from tf.keras.model\n",
        "\t\tdef __init__(self, mode): # Define All your Variables Here. And other configurations\n",
        "\t\t\t\tsuper(CALTEXT_Model, self).__init__()\n",
        "\t\t\t\tself.dense_blocks=dense_block\n",
        "\t\t\t\tself.levels_count=16\n",
        "\t\t\t\tself.growth=24\n",
        "\n",
        "\t\t\t\t#### decoder setup parameters ####\n",
        "\t\t\t\tself.hidden_dim=256\n",
        "\t\t\t\tself.word_dim=256\n",
        "\t\t\t\tself.dim_attend=512\n",
        "\t\t\t\tself.dense_encoder =  DenseEncoder(blocks=self.dense_blocks,level=self.levels_count, growth_rate=self.growth, istraining=mode)\n",
        "\t\t\t\tself.contextual_attention = ContextualAttention(684, self.hidden_dim, self.dim_attend)\n",
        "\t\t\t\tself.decoder = Decoder(self.hidden_dim, self.word_dim, self.contextual_attention, 684)\t##annotation.shape.as_list()[3]=684\n",
        "\t\t\t\tself.caltext = CALText(self.dense_encoder, self.contextual_attention, self.decoder, self.hidden_dim, self.word_dim, 684 ,num_classes ,istraining=mode)\n",
        "\n",
        "\n",
        "\t\tdef call(self, x, y, x_mask, y_mask, training): # Use the variables defined here.... this is forward prop\n",
        "\t\t\t\tannotation, anno_mask = self.dense_encoder.dense_net(x, x_mask)\n",
        "\t\t\t\t#print(annotation.shape)\n",
        "\t\t\t\tcost = self.caltext.get_cost(annotation, y, anno_mask, y_mask, gamma_val)\n",
        "\t\t\t\treturn cost,annotation\n",
        "\n",
        "\t\tdef get_hidden_state_0(self, anno):\n",
        "\t\t\t\thidden_state_0 = tf.tanh(tf.tensordot(tf.reduce_mean(input_tensor=anno, axis=[1, 2]), self.caltext.Wa2h, axes=1) + self.caltext.ba2h)  # [batch, hidden_dim]\n",
        "\t\t\t\treturn hidden_state_0\n"
      ],
      "metadata": {
        "id": "qS13h7g7Y_oG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#this is the start of the code\n",
        "\n",
        "####Load train and valid data from pickle files\n",
        "train, train_uid_list =load_data('/content/gdrive/My Drive/Experiment1/data/train_images.pkl','/content/gdrive/My Drive/Experiment1/data/train_labels.pkl')\n",
        "valid, valid_uid_list =load_data('/content/gdrive/My Drive/Experiment1/data/valid_images.pkl','/content/gdrive/My Drive/Experiment1/data/valid_labels.pkl')\n",
        "test, test_uid_list =load_data('/content/gdrive/My Drive/Experiment1/data/test_images.pkl','/content/gdrive/My Drive/Experiment1/data/test_labels.pkl')\n",
        "worddicts,_ = load_dict_picklefile('/content/gdrive/My Drive/Experiment1/data/vocabulary.pkl')\n",
        "\n",
        "# Take half of the training data\n",
        "train = train[:len(train) // 2]\n",
        "train_uid_list = train_uid_list[:len(train_uid_list) // 2]\n",
        "\n",
        "# Take half of the validation data\n",
        "valid = valid[:len(valid) // 2]\n",
        "valid_uid_list = valid_uid_list[:len(valid_uid_list) // 2]\n",
        "\n",
        "# Take half of the testing data\n",
        "test = test[:len(test) // 2]\n",
        "test_uid_list = test_uid_list[:len(test_uid_list) // 2]\n",
        "\n",
        "num_classes = len(worddicts)\n",
        "print(num_classes)\n",
        "\n",
        "worddicts_r = [None] * len(worddicts)\n",
        "i=1\n",
        "for kk, vv in worddicts.items():\n",
        "    if(i<len(worddicts)):\n",
        "        worddicts_r[vv] = kk\n",
        "    else:\n",
        "        break\n",
        "    i=i+1\n",
        "\n",
        "\n",
        "# Create an instance of the model\n",
        "model = CALTEXT_Model(mode=True)\n",
        "#model.load_weights('/content/gdrive/My Drive/MultiScaleAttention/caltextModel/cp-0002.ckpt')\n",
        "\n",
        "optimizer= tf.keras.optimizers.Adadelta(1.0)\n",
        "\n",
        "# Variables for epochs and iterations\n",
        "epoch_var = tf.Variable(0, dtype=tf.int64, trainable=False)\n",
        "iter_var = tf.Variable(0, dtype=tf.int64, trainable=False)\n",
        "\n",
        "# Paths for checkpoints\n",
        "checkpoint_path = \"/content/gdrive/My Drive/Experiment1/checkpoints/cp-{epoch:04d}-iter-{iter:04d}.ckpt\"\n",
        "\n",
        "# Create checkpoint and manager\n",
        "checkpoint = tf.train.Checkpoint(step=iter_var, epoch=epoch_var, model=model, optimizer=optimizer)\n",
        "checkpoint_manager = tf.train.CheckpointManager(checkpoint, directory=os.path.dirname(checkpoint_path), max_to_keep=5)\n",
        "\n",
        "#take the mean of loss from batch\n",
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "valid_loss = tf.keras.metrics.Mean(name='valid_loss')\n",
        "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
        "\n",
        "@tf.function(experimental_relax_shapes=True)\n",
        "def train_step(x, x_mask,y,y_mask, training=True):\n",
        "  if(training):\n",
        "    with tf.GradientTape() as tape:\n",
        "      # training=True is only needed if there are layers with different\n",
        "      # behavior during training versus inference (e.g. Dropout).\n",
        "\n",
        "      loss,anno = model(x,y, x_mask,y_mask, training=True)\n",
        "\n",
        "      #loss=get_loss(loss,model)#apply L2 regularization on weights\n",
        "\n",
        "    gradients = tape.gradient(loss, model.trainable_variables)\n",
        "    clipped_gradients, _ = tf.clip_by_global_norm(gradients ,100)\n",
        "    optimizer.apply_gradients(zip(clipped_gradients,model.trainable_variables))\n",
        "    train_loss(loss)\n",
        "    #return loss, anno, hidden_state_0\n",
        "  else:\n",
        "    loss,anno = model(x, y,x_mask,y_mask, training=False)\n",
        "    #loss=get_loss(loss,model)#apply L2 regularization on weights\n",
        "    train_loss(loss)\n",
        "\n",
        "  hidden_state_0 = model.get_hidden_state_0(anno)\n",
        "  return loss,anno,hidden_state_0\n",
        "\n",
        "@tf.function(experimental_relax_shapes=True)\n",
        "def valid_step(x, x_mask,y,y_mask):\n",
        "  # training=False is only needed if there are layers with different\n",
        "  # behavior during training versus inference (e.g. Dropout).\n",
        "  loss,anno = model(x, y,x_mask,y_mask, training=False)\n",
        "\n",
        "  #loss=get_loss(loss,model)#apply L2 regularization on weights\n",
        "  valid_loss(loss)\n",
        "  hidden_state_0 = model.get_hidden_state_0(anno)\n",
        "  return loss,anno,hidden_state_0\n",
        "\n",
        "\n",
        "@tf.function(experimental_relax_shapes=True)\n",
        "def execute_model(xx,xx_mask,yy,yy_mask,model):\n",
        "  loss,anno = model(xx,yy,xx_mask,yy_mask, training=False)\n",
        "  test_loss(loss)\n",
        "  hidden_state_0 = model.get_hidden_state_0(anno)\n",
        "  return loss,anno,hidden_state_0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3MQq6qjHZ-Pp",
        "outputId": "dbb291b8-88ff-478c-fcc5-6f544eebcabf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "333\n",
            "total  167 batch data loaded\n",
            "58\n",
            "total  29 batch data loaded\n",
            "61\n",
            "total  31 batch data loaded\n",
            "131\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_val_loss = float('inf')\n",
        "best_model_path = \"/content/gdrive/My Drive/Experiment1/model/best_model.weights.h5\"\n",
        "# Load the latest checkpoint if it exists\n",
        "if checkpoint_manager.latest_checkpoint:\n",
        "    checkpoint.restore(checkpoint_manager.latest_checkpoint).expect_partial()  # Allow partial restore\n",
        "    print(f\"Restored from {checkpoint_manager.latest_checkpoint} at epoch {int(epoch_var)}, iteration {int(iter_var)}\")\n",
        "\n",
        "    # Check if the iteration count exceeds the length of the dataset (i.e., epoch completed)\n",
        "    if int(iter_var) >= len(train):  # If the last saved iteration marks the end of an epoch\n",
        "        epoch_var.assign(int(epoch_var) + 1)  # Move to the next epoch\n",
        "        iter_var.assign(0)  # Reset iteration to 0 for the new epoch\n",
        "        print(f\"Completed epoch, starting from epoch {int(epoch_var)} and first iteration.\")\n",
        "else:\n",
        "    print(\"Starting training from scratch.\")\n",
        "    epoch_var.assign(0)\n",
        "    iter_var.assign(0)\n",
        "\n",
        "EPOCHS = 31\n",
        "train_loss_array = []\n",
        "valid_loss_array = []\n",
        "test_loss_array = []\n",
        "\n",
        "# Start training\n",
        "for epoch in range(int(epoch_var), EPOCHS):\n",
        "    # Reset the metrics at the start of the next epoch\n",
        "    train_loss.reset_state()\n",
        "    valid_loss.reset_state()\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Determine if we need to shuffle the training data\n",
        "    if epoch > int(epoch_var):  # If starting a new epoch, shuffle\n",
        "        random.shuffle(train)\n",
        "        print('after shuffle done')\n",
        "\n",
        "    # Train in batches without using `enumerate`\n",
        "    iter_num = int(iter_var)  # Initialize iter_num with checkpointed iteration count\n",
        "    current_batch_index = iter_num % len(train)  # Calculate starting batch based on iter_num\n",
        "\n",
        "    # Continue training from the last completed batch\n",
        "    for batch_index in range(current_batch_index, len(train)):\n",
        "        images, labels = train[batch_index]\n",
        "        print(batch_index)\n",
        "        # Prepare the data\n",
        "        x, x_mask, y, y_mask = prepare(images, labels)\n",
        "        print(iter_num)\n",
        "\n",
        "        # Training step\n",
        "        loss, anno, hidden_state_0 = train_step(x, x_mask, y, y_mask, True)\n",
        "\n",
        "        # Save checkpoint after every 5 iterations\n",
        "        if iter_num % 5 == 0:\n",
        "            iter_var.assign(iter_num)  # Save iteration\n",
        "            epoch_var.assign(epoch)  # Save epoch\n",
        "            checkpoint_manager.save()\n",
        "            print(f\"Checkpoint saved at iteration {iter_num}\")\n",
        "\n",
        "        # Increment the iteration number\n",
        "        iter_num += 1\n",
        "\n",
        "\n",
        "    total_train_loss = 0\n",
        "    for train_images, train_labels in train:\n",
        "        x, x_mask, y, y_mask = prepare(train_images, train_labels)\n",
        "        loss, anno, hidden_state_0 = train_step(x, x_mask, y, y_mask, False)\n",
        "        total_train_loss += loss\n",
        "\n",
        "    avg_train_loss = total_train_loss / len(train)\n",
        "\n",
        "    total_valid_loss = 0\n",
        "    for valid_images, valid_labels in valid:\n",
        "        x, x_mask, y, y_mask = prepare(valid_images, valid_labels)\n",
        "        loss,anno,hidden_state_0 = valid_step(x,x_mask,y,y_mask)\n",
        "        total_valid_loss += loss\n",
        "\n",
        "    avg_valid_loss = total_valid_loss / len(valid)\n",
        "\n",
        "    if avg_valid_loss < best_val_loss:\n",
        "        best_val_loss = avg_valid_loss\n",
        "        model.save_weights(best_model_path)\n",
        "\n",
        "    total_test_loss = 0\n",
        "    for test_images, test_labels in test:\n",
        "        x, x_mask, y, y_mask = prepare(test_images, test_labels)\n",
        "        loss,anno,hidden_state_0 = execute_model(x,x_mask,y,y_mask, model)\n",
        "        total_test_loss += loss\n",
        "\n",
        "    avg_test_loss = total_test_loss / len(test)\n",
        "\n",
        "    duration = time.time() - start_time\n",
        "\n",
        "    train_loss_array.append(avg_train_loss)\n",
        "    valid_loss_array.append(avg_valid_loss)\n",
        "    test_loss_array.append(avg_test_loss)\n",
        "\n",
        "    print(f'Epoch: {epoch}, Time: {duration}, Train_Loss: {train_loss.result()}, Validation_Loss: {valid_loss.result()}, Test_Loss: {test_loss.result()}')\n",
        "    # After every epoch, reset iteration and save the model\n",
        "    iter_var.assign(0)\n",
        "    epoch_var.assign(epoch + 1)  # Move to the next epoch\n",
        "    checkpoint_manager.save()  # Save checkpoint at the end of each epoch\n",
        "    print(f\"Epoch {epoch} completed and checkpoint saved.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_LllfQq3a8Qp",
        "outputId": "9b401d29-9674-4621-d30d-f826eded3f5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training from scratch.\n",
            "0\n",
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py:391: UserWarning: `build()` was called on layer 'caltext__model_3', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    }
  ]
}